{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing a roll call pdf\n",
    "> Extracting the relevant information from a roll call vote PDF file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyPDF2 docs: https://pythonhosted.org/PyPDF2/PdfFileReader.html\n",
    "\n",
    "PyPDF2 `PageObject`: https://pythonhosted.org/PyPDF2/PageObject.html#PyPDF2.pdf.PageObject\n",
    "\n",
    "EU pdfs: https://www.europarl.europa.eu/plenary/en/votes.html?tab=votes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDF content:\n",
    "- intro\n",
    "- table of contents\n",
    "- votes for issue:\n",
    "    - each issue ma also have vote corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import PyPDF2 as pdf\n",
    "from pathlib import Path\n",
    "import typing\n",
    "import re\n",
    "import pandas as pd\n",
    "import collections\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('PV-9-2020-07-23-RCV_FR.pdf'); path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('PV-9-2020-07-08-RCV_EN.pdf'); path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fobj = open(path, 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = pdf.PdfFileReader(fobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader.getNumPages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_texts = [reader.getPage(i).extractText() for i in range(reader.getNumPages())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_ix(strings:typing.List[str], pattern_fun:typing.Callable): # , must_match:bool=True\n",
    "    #print(strings)\n",
    "    return [i for i, s in enumerate(strings) if pattern_fun(s)] # (must_match and s==pattern) or (not must_match and pattern in s)\n",
    "\n",
    "def useful_string(s):  return ('docx' not in s) and (len(s)>0) \\\n",
    "            and (s != ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SummaryParser:\n",
    "    \n",
    "    pattern = re.compile('(\\.\\.+)')\n",
    "    is_toc = lambda self, text: 'SOMMAIRE' in text or 'CONTENTS' in text\n",
    "    \n",
    "    def __init__(self, all_texts:typing.List[str]):\n",
    "        \n",
    "        self.num_pages = len(all_texts)\n",
    "        \n",
    "        self.ix_start, summary_text = self.get_start(all_texts)\n",
    "\n",
    "        self.vote_names, self.vote_page_numbers = self.parse_names_and_page_numbers(summary_text)\n",
    "        \n",
    "        self.ix_end, summary_text = self.get_end(all_texts, summary_text)\n",
    "        \n",
    "        if self.ix_end > self.ix_start:\n",
    "            self.vote_names, self.vote_page_numbers = self.parse_names_and_page_numbers(summary_text)\n",
    "        \n",
    "    def get_start(self, all_texts:typing.List[str]): \n",
    "        ix_start = get_ix(all_texts, self.is_toc)[0]        \n",
    "        return ix_start, all_texts[ix_start]\n",
    "        \n",
    "    def parse_names_and_page_numbers(self, all_texts:typing.List[str]): \n",
    "        texts = re.split(r'(\\d+\\.)(\\s*[a-zA-Z])', all_texts)\n",
    "        \n",
    "        ix_content = get_ix(texts, self.is_toc)[0]\n",
    "        texts = texts[ix_content+1:]\n",
    "\n",
    "        given_number = texts[::3]\n",
    "\n",
    "        contents = [text0.strip()+text1.strip() for text0, text1 in zip(texts[1::3],\n",
    "                                                                        texts[2::3])]\n",
    "        page_numbers, vote_names = [], []\n",
    "        \n",
    "        for text in contents:\n",
    "            if 'docx' in text:\n",
    "                _text = text.split('\\n')\n",
    "                _ix = get_ix(_text, lambda x: 'docx' in x)[0]\n",
    "                _text = '\\n'.join(_text[:_ix])\n",
    "            else:\n",
    "                _text = text\n",
    "            try:\n",
    "                re.search(r'(\\d+)$', _text).group()\n",
    "            except:\n",
    "                print('failed at parsing', [text], 'to', [_text])\n",
    "                \n",
    "            page_numbers.append(int(re.search(r'(\\d+)$', _text).group()))\n",
    "            vote_names.append(re.sub(r'\\.*\\d+$', '', _text).strip())\n",
    "        \n",
    "        assert len(vote_names) == len(page_numbers)\n",
    "        assert len(set(page_numbers)) == len(page_numbers), collections.Counter(page_numbers).most_common()\n",
    "        \n",
    "        return vote_names, [nr-1 for nr in page_numbers]\n",
    "        \n",
    "    def get_end(self, all_texts:typing.List[str], summary_text:str): \n",
    "        \n",
    "        if self.ix_start + 1 == self.vote_page_numbers[0]:\n",
    "            return self.ix_start, summary_text\n",
    "        \n",
    "        ix_end = self.vote_page_numbers[0]\n",
    "        summary_text = '\\n'.join(all_texts[self.ix_start:ix_end])\n",
    "        \n",
    "        return ix_end, summary_text\n",
    "    \n",
    "    @property\n",
    "    def df(self):\n",
    "        return pd.DataFrame({\n",
    "            'vote name': self.vote_names,\n",
    "            'start page': self.vote_page_numbers,\n",
    "            'end page': [nr - 1 for nr in self.vote_page_numbers[1:]] + [self.num_pages]\n",
    "        })\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = SummaryParser(all_texts)\n",
    "df_summary = summary.df\n",
    "df_summary.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 150):\n",
    "    display(df_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class VotesParser:\n",
    "    \n",
    "    def __init__(self, start_page:int, end_page:int, all_texts:typing.List[str]):\n",
    "        '`end_page` is inclusive'\n",
    "        assert start_page <= end_page\n",
    "        self.start_page = start_page\n",
    "        self.end_page = end_page\n",
    "        \n",
    "        votes_texts = self.preprocess(all_texts)\n",
    "        \n",
    "        original_votes, vote_corrections = self.check_for_corrections(votes_texts)\n",
    "        \n",
    "        #print(original_votes, vote_corrections)\n",
    "        \n",
    "        self.vote_counts, self.votes = self.parse_votes(original_votes)\n",
    "        \n",
    "        if vote_corrections is not None:\n",
    "            self.corrections = self.parse_vote_corrections(vote_corrections)\n",
    "    \n",
    "    @property\n",
    "    def df_votes(self):\n",
    "        df = []\n",
    "        for outcome in self.votes:\n",
    "            for party in self.votes[outcome]:\n",
    "                df.extend([(mep, outcome, party) for mep in self.votes[outcome][party]])\n",
    "        return pd.DataFrame(df, columns=['MEP', 'vote', 'Party'])\n",
    "    \n",
    "    @property\n",
    "    def df_corrections(self):\n",
    "        df = []\n",
    "        for outcome in self.votes:\n",
    "            df.extend([(mep, outcome) for mep in self.corrections[outcome]])\n",
    "        return pd.DataFrame(df, columns=['MEP', 'vote'])\n",
    "    \n",
    "    def preprocess(self, all_texts:typing.List[str]):\n",
    "        votes_texts = \"\\n\".join(all_texts[self.start_page:self.end_page+1])\n",
    "        \n",
    "        s = slice(self.start_page, self.end_page+1)\n",
    "        votes_texts = \"\\n\".join(all_texts[s]).split(\"\\n\")\n",
    "        \n",
    "        votes_texts = [text for text in votes_texts if \\\n",
    "                       useful_string(text)]\n",
    "        return votes_texts\n",
    "    \n",
    "    def parse_votes(self, votes_texts:typing.List[str]):\n",
    "        #print(votes_texts)\n",
    "        \n",
    "        ix_yes, ix_no, ix_abstain = self.get_yes_no_abstain_indices(votes_texts)\n",
    "        \n",
    "        counts = {\n",
    "            'yes': int(votes_texts[ix_yes-1]),\n",
    "            'no': int(votes_texts[ix_no-1]),\n",
    "            'abstain': int(votes_texts[ix_abstain-1]),\n",
    "        }\n",
    "        votes = {\n",
    "            'yes': self.get_mep_and_party_vote_for_outcome(votes_texts[ix_yes:ix_no-1]),\n",
    "            'no': self.get_mep_and_party_vote_for_outcome(votes_texts[ix_no:ix_abstain-1]),\n",
    "            'abstain': self.get_mep_and_party_vote_for_outcome(votes_texts[ix_abstain:])\n",
    "        }\n",
    "        #print(counts)\n",
    "        #print([(k, (x:=[len(val) for val in v.values()]), sum(x)) for k,v in votes.items()])\n",
    "        return counts, votes\n",
    "    \n",
    "    def get_yes_no_abstain_indices(self, votes_texts):\n",
    "        ix_yes = min(get_ix(votes_texts, lambda x: x == '+'))\n",
    "        ix_no = get_ix(votes_texts, lambda x: x == '-')[0]\n",
    "        ix_abstain = max(get_ix(votes_texts, lambda x: x == '0'))\n",
    "        assert ix_yes > 0\n",
    "        assert ix_yes < ix_no\n",
    "        assert ix_no < ix_abstain\n",
    "        return ix_yes, ix_no, ix_abstain\n",
    "    \n",
    "    def parse_vote_corrections(self, votes_corrections_texts:typing.List[str]): \n",
    "\n",
    "        ix_yes, ix_no, ix_abstain = self.get_yes_no_abstain_indices(votes_corrections_texts)\n",
    "        \n",
    "        yes_meps = '\\n'.join(votes_corrections_texts[ix_yes+1:ix_no]).split(',')\n",
    "        no_meps = '\\n'.join(votes_corrections_texts[ix_no+1:ix_abstain]).split(',')\n",
    "        abstain_meps = '\\n'.join(votes_corrections_texts[ix_abstain+1:]).split(',')\n",
    "        \n",
    "        return {\n",
    "            'yes': [self.process_mep(mep) for mep in yes_meps if useful_string(mep.strip())],\n",
    "            'no': [self.process_mep(mep) for mep in no_meps if useful_string(mep.strip())],\n",
    "            'abstain': [self.process_mep(mep) for mep in abstain_meps if useful_string(mep.strip())]\n",
    "        }\n",
    "        \n",
    "    def get_mep_and_party_vote_for_outcome(self, votes_texts:typing.List[str]):\n",
    "\n",
    "        ix_party = [(i,text) for i, text in enumerate(votes_texts)\\\n",
    "                    if len(text)>0 and (':' == text[0] or ':' == text[-1])]\n",
    "        \n",
    "        ix_party = [i if (text[-1]==':' and len(text)>1) else i-1 for i, text in ix_party]\n",
    "        parties = [votes_texts[ix] for ix in ix_party]\n",
    "        meps = [','.join(votes_texts[ix0+1:ix1]).split(',') for ix0, ix1 in \n",
    "                zip(ix_party, ix_party[1:]+[len(votes_texts)])]\n",
    "        votes = {party: [self.process_mep(mep) for mep in _meps if useful_string(mep.strip())] for party, _meps in zip(parties, meps)}\n",
    "        \n",
    "        return votes\n",
    "    \n",
    "    def process_mep(self, mep:str, placeholder:str='unknown mep'):\n",
    "        mep = mep.strip()\n",
    "        if ':' in mep:\n",
    "            if mep.startswith(':'):\n",
    "                mep = mep[1:]\n",
    "            if mep.endswith(':'):\n",
    "                mep = mep[:-1]\n",
    "        if mep == '':\n",
    "            mep = placeholder\n",
    "        return mep\n",
    "        \n",
    "    def check_for_corrections(self, votes_texts:typing.List[str]): \n",
    "        \n",
    "        ix = get_ix(votes_texts, lambda x: 'CORRECCIONES E INTENCIONES DE VOTO' in x)\n",
    "        assert len(ix) <= 1\n",
    "        no_corrections = len(ix) == 0\n",
    "        if no_corrections:\n",
    "            return votes_texts, None\n",
    "        else:\n",
    "            return votes_texts[:ix[0]], votes_texts[ix[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "- Some MEP names seem to disappear when reading the PDF, like Kolakušić, and some are incorrectly read like Ždanoka $\\rightarrow$ ”danoka\n",
    "- the total vote count and the counted names of the actually parsed MEPs disagrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start, end = summary.df.iloc[0,1:]\n",
    "votes = VotesParser(start, end, all_texts)\n",
    "display(votes.df_votes, votes.df_corrections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = summary.df\n",
    "df_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing all issues voted on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_all_issues(df_summary:pd.DataFrame, all_texts:typing.List[str]):\n",
    "    all_votes, all_corrections = [], []\n",
    "    all_counts = []\n",
    "\n",
    "    for i,row in df_summary.iterrows():\n",
    "        votes = VotesParser(row['start page'], row['end page'], all_texts)\n",
    "\n",
    "        df_votes = votes.df_votes\n",
    "        df_votes['vote name'] = row['vote name']\n",
    "        all_votes.append(df_votes)\n",
    "\n",
    "        counts = votes.vote_counts\n",
    "        counts['vote name'] = row['vote name']\n",
    "        all_counts.append(counts)\n",
    "\n",
    "        df_corrections = votes.df_corrections\n",
    "        df_corrections['vote name'] = row['vote name']\n",
    "        all_corrections.append(df_corrections)\n",
    "\n",
    "    all_counts = pd.DataFrame(all_counts)\n",
    "    all_votes = pd.concat(all_votes)\n",
    "    all_corrections = pd.concat(all_corrections)\n",
    "    return all_counts, all_votes, all_corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_counts, all_votes, all_corrections = get_all_issues(df_summary, all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counts.head(), all_counts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_votes.head(), all_votes.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlap between vote names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = set(all_counts['vote name'].unique())\n",
    "s2 = set(all_votes['vote name'].unique())\n",
    "\n",
    "assert len(s1.intersection(s2))/len(s1.union(s2)) == 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of total counts vs identified counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_votes_summed = all_counts.copy()\n",
    "outcomes = ['yes', 'no', 'abstain']\n",
    "all_votes_summed.loc[:,outcomes] = None\n",
    "\n",
    "for outcome in outcomes:\n",
    "    vote_mask = all_votes['vote'] == outcome\n",
    "    \n",
    "    for vote in all_votes['vote name'].unique():\n",
    "        mask = all_votes_summed['vote name'] == vote\n",
    "        _votes = (all_votes['vote name'] == vote) & vote_mask\n",
    "        all_votes_summed.loc[mask, outcome] = _votes.sum()\n",
    "    \n",
    "    all_votes_summed[outcome] = all_votes_summed[outcome].astype(int)\n",
    "    all_votes_summed[f'{outcome}-delta'] = all_votes_summed[outcome] - all_counts[outcome]\n",
    "        \n",
    "all_votes_summed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_votes_summed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.melt(all_votes_summed, value_vars=['yes','no','abstain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = pd.melt(all_votes_summed, value_vars=[v for v in all_votes_summed.columns if 'delta' in v])\n",
    "deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(deltas.groupby('variable').describe())\n",
    "px.histogram(data_frame=deltas,\n",
    "             x=f'value',\n",
    "             color='variable',\n",
    "             barmode='overlay', nbins=21,\n",
    "             title=f'Discrepancy for \\'{outcome}\\' votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38_pdf_docs]",
   "language": "python",
   "name": "conda-env-py38_pdf_docs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
